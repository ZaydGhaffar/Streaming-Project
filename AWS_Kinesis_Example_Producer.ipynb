{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teipSDS2a5Of",
        "outputId": "d40b8b57-31d8-4930-a842-19620a534733"
      },
      "outputs": [],
      "source": [
        "# if you run into an error you may need to run this twice\n",
        "!pip install boto3\n",
        "!pip install aws-kinesis-agg\n",
        "!pip install s3fs\n",
        "!pip install pyarrow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC557PKIbPCJ"
      },
      "source": [
        "**Make sure to create an `aws.cfg` file and upload it here**\n",
        "\n",
        "aws.cfg example:\n",
        "\n",
        "```\n",
        "[AWS]\n",
        "aws_access_key_id = youraccesskey\n",
        "aws_secret_access_key = yoursecretkey\n",
        "region_name=us-east-1\n",
        "```\n",
        "Make sure to change the values to match yours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQf-JjBxag0E"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import configparser\n",
        "\n",
        "# Read AWS credentials from config file\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read('aws.cfg')\n",
        "\n",
        "aws_access_key_id = config['AWS']['aws_access_key_id']\n",
        "aws_secret_access_key = config['AWS']['aws_secret_access_key']\n",
        "region_name = config['AWS']['region_name']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thhDB1sXa3ip"
      },
      "outputs": [],
      "source": [
        "# Initialize the boto3 client with credentials from config file\n",
        "kinesis_client = boto3.client(\n",
        "    'kinesis',\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key,\n",
        "    region_name=region_name\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcPWqN7WbqI5"
      },
      "outputs": [],
      "source": [
        "def produce(stream_name, data, partition_key):\n",
        "    try:\n",
        "        # Convert timestamps to strings\n",
        "        for key in data:\n",
        "            if isinstance(data[key], pd.Timestamp):\n",
        "                data[key] = data[key].isoformat()\n",
        "                # using the put_record method to push the stream\n",
        "        response = kinesis_client.put_record(\n",
        "            StreamName=stream_name,\n",
        "            Data=json.dumps(data),\n",
        "            PartitionKey=partition_key\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error producing record: {e}\")\n",
        "\n",
        "# this function takes 5 records at a time and streams every 2-seconds\n",
        "def stream_data(df, stream_name):\n",
        "    for i in range(0, len(df), 5):\n",
        "        records = df.iloc[i:i+5].to_dict(orient='records')\n",
        "        for record in records:\n",
        "            partition_key = str(record['tpep_pickup_datetime'])  # Use a valid column as the partition key\n",
        "\n",
        "            # call the produce function\n",
        "            produce(stream_name, record, partition_key)\n",
        "        print(f\"Sent {len(records)} records to Kinesis\")\n",
        "        time.sleep(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZRrzhtUbt64"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    stream_name = 'zayd-input-stream'\n",
        "    # Reading the yellow_taxis parquet file and stream it\n",
        "    df = pd.read_parquet('s3://techcatalyst-public/yellow_tripdata_2024-01.parquet',\n",
        "                     storage_options={\n",
        "                      'key': aws_access_key_id,\n",
        "                     'secret': aws_secret_access_key,\n",
        "                     })\n",
        "    stream_data(df, stream_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzcIQPLicIuv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
